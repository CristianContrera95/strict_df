{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"StrictDataFrame The Pandas DataFrames can handle mixed data types on the columns: for instance, a column \"month\" can have both integer and string values, being \"object\" the data type associated in those cases. This ability could result in undesired side effects in several use cases, especially on data pipelines where it is necessary to know the type of data processed over the steps. This is a library that provides utils to handle Pandas DataFrames in a \"strict\" way regarding the data schema, so a DataFrame enforces a proper data type for each of its columns, as well as other related utils. Quickstart Installation Installing strictdf is done in the usual ways. The simplest way is with pip: pip install git+git://github.com/CristianContrera95/strict_df.git Note: It is very important to install strictdf on the correct version of Python. StrictDataFrame requires Python>=3.9 . If spark is installed already, strictdf will use it on some methods. Using stricdf To start using stricdf , open an jupyter or ipython sheel and run: from strictdf import StrictDataFrame df = pd.read_csv('data.csv') sdf = StrictDataFrame(df) sdf.dtypes # {'serious_dlqin2yrs': 'bool', # 'revolving_utilization_of_unsecured_lines': 'float64', # 'age': 'int64', # 'number_of_time30-59_days_past_due_not_worse': 'int64', # 'debt_ratio': 'float64', # 'monthly_income': 'int64' # } sdf.report() # \"DataFrame having shape '(120157, 11)' (29843 rows removed from original)\" API This part of the documentation covers all the interfaces of strictdf StrictDataFrame The StrictDataFrame class implements strict dtypes for DataFrames columns StrictDataFrame ( df , min_percentage : Union[int, float] = 90, impute : bool = False, binary2bool : bool = False, skip_col : Union[List, np.array] = None) from strictdf import StrictDataFrame StrictDataFrame is a pd.DataFrame wrapper that provides utilities to handle in a \"strict\" DataFrames way with respect to the data schema, so it imposes a suitable data type for each of its columns Parameters df : pandas DataFrame Contains data stored in DataFrame. min_percentage : int or float optional (default=.90) Values must be between 0 and 100 or 0. and 1. (if float if given) Used to determine the type of a column, requires 'min_percentage' of rows to be 1 expected type impute : bool optional (default=False) binary2bool : bool optional (default=False) Attributes old_df : pd.DataFrame Original pd.DataFrame given new_df : pd.DataFrame Modified pd.DataFrame with \"strict\" types for each column impute : bool (default=False) Impute values that are being removed to not meet expected data types. For columns float 'mean' is used, for integer 'mode' is used binary2bool : bool (default=False) Convert all columns with only 2 values to boolean skip_col : list or array-like Column names to be omitted Methods report() : Prints current df's shape and diff with original df to_spark() : Convert new_df attribute in sparkDataFrame and return it Note: If spark is not installed to_report() does nothing. Utils The module provides common functions used in several code parts Utils.dtypes This module implements function to infer data types Functions str_check_bool( string ) : Check if given string is bool str_check_int( string ) : Check if given string is int str_check_float( string ) : Check if given string is float dataset This module only for develops purposes Function load_credit_data() : Allow a download csv file to test StrictDataFrame","title":"Home"},{"location":"#strictdataframe","text":"The Pandas DataFrames can handle mixed data types on the columns: for instance, a column \"month\" can have both integer and string values, being \"object\" the data type associated in those cases. This ability could result in undesired side effects in several use cases, especially on data pipelines where it is necessary to know the type of data processed over the steps. This is a library that provides utils to handle Pandas DataFrames in a \"strict\" way regarding the data schema, so a DataFrame enforces a proper data type for each of its columns, as well as other related utils.","title":"StrictDataFrame"},{"location":"#quickstart","text":"","title":"Quickstart"},{"location":"#installation","text":"Installing strictdf is done in the usual ways. The simplest way is with pip: pip install git+git://github.com/CristianContrera95/strict_df.git Note: It is very important to install strictdf on the correct version of Python. StrictDataFrame requires Python>=3.9 . If spark is installed already, strictdf will use it on some methods.","title":"Installation"},{"location":"#using-stricdf","text":"To start using stricdf , open an jupyter or ipython sheel and run: from strictdf import StrictDataFrame df = pd.read_csv('data.csv') sdf = StrictDataFrame(df) sdf.dtypes # {'serious_dlqin2yrs': 'bool', # 'revolving_utilization_of_unsecured_lines': 'float64', # 'age': 'int64', # 'number_of_time30-59_days_past_due_not_worse': 'int64', # 'debt_ratio': 'float64', # 'monthly_income': 'int64' # } sdf.report() # \"DataFrame having shape '(120157, 11)' (29843 rows removed from original)\"","title":"Using stricdf"},{"location":"#api","text":"This part of the documentation covers all the interfaces of strictdf","title":"API"},{"location":"#strictdataframe_1","text":"The StrictDataFrame class implements strict dtypes for DataFrames columns StrictDataFrame ( df , min_percentage : Union[int, float] = 90, impute : bool = False, binary2bool : bool = False, skip_col : Union[List, np.array] = None) from strictdf import StrictDataFrame StrictDataFrame is a pd.DataFrame wrapper that provides utilities to handle in a \"strict\" DataFrames way with respect to the data schema, so it imposes a suitable data type for each of its columns","title":"StrictDataFrame"},{"location":"#parameters","text":"df : pandas DataFrame Contains data stored in DataFrame. min_percentage : int or float optional (default=.90) Values must be between 0 and 100 or 0. and 1. (if float if given) Used to determine the type of a column, requires 'min_percentage' of rows to be 1 expected type impute : bool optional (default=False) binary2bool : bool optional (default=False)","title":"Parameters"},{"location":"#attributes","text":"old_df : pd.DataFrame Original pd.DataFrame given new_df : pd.DataFrame Modified pd.DataFrame with \"strict\" types for each column impute : bool (default=False) Impute values that are being removed to not meet expected data types. For columns float 'mean' is used, for integer 'mode' is used binary2bool : bool (default=False) Convert all columns with only 2 values to boolean skip_col : list or array-like Column names to be omitted","title":"Attributes"},{"location":"#methods","text":"report() : Prints current df's shape and diff with original df to_spark() : Convert new_df attribute in sparkDataFrame and return it Note: If spark is not installed to_report() does nothing.","title":"Methods"},{"location":"#utils","text":"The module provides common functions used in several code parts","title":"Utils"},{"location":"#utilsdtypes","text":"This module implements function to infer data types","title":"Utils.dtypes"},{"location":"#functions","text":"str_check_bool( string ) : Check if given string is bool str_check_int( string ) : Check if given string is int str_check_float( string ) : Check if given string is float","title":"Functions"},{"location":"#dataset","text":"This module only for develops purposes","title":"dataset"},{"location":"#function","text":"load_credit_data() : Allow a download csv file to test StrictDataFrame","title":"Function"},{"location":"about/","text":"StrictDataFrame Thank for all! I'm Cristian Contrera trying get a new job :)","title":"About"},{"location":"about/#strictdataframe","text":"Thank for all! I'm Cristian Contrera trying get a new job :)","title":"StrictDataFrame"},{"location":"developers/","text":"StrictDataFrame The Pandas DataFrames can handle mixed data types on the columns: for instance, a column \"month\" can have both integer and string values, being \"object\" the data type associated in those cases. This ability could result in undesired side effects in several use cases, especially on data pipelines where it is necessary to know the type of data processed over the steps. This is a library that provides utils to handle Pandas DataFrames in a \"strict\" way regarding the data schema, so a DataFrame enforces a proper data type for each of its columns, as well as other related utils. Developers guide Installing dev mode Installing strictdf dev mode is done in the usual ways. Github You can download the project from github repository and create a distribution wheel from code. Open a bash shell in the root of project and run: chmod +x script/library_create.sh ./script/library_create.sh if you are using windows os, you are starting very very bad. Anyway library_create.bat for windows is provided. Those commands should create two folders build and dist Now can install with pip following: pip install dist/strictdf-0.1.0-py3-none-any.whl[dev] Note: It is very important to install strictdf on the correct version of Python. StrictDataFrame requires Python>=3.9 . Note: Install strictdf on dev mode allow run test and check coverage. Run Tests To run test, You must download strictdf from github (previous section) and follow one of the following paths Docker Using Dockerfile provided, You can build docker image, it's very easy, only open a bash shell and run: chmod +x script/build_docker.sh ./script/build_docker.sh Note: If you don't need spark , you can comment the lines indicated in the Dockerfile And when this ends: docker run -it strict_df_test Hands With a shell in the root of the project, run: chmod +x script/create_env.sh chmod +x script/run_test.sh create_env.sh run_test.sh Note: To perform this, you need install python3.9 with pyenv and pip for that python version.","title":"Developers"},{"location":"developers/#strictdataframe","text":"The Pandas DataFrames can handle mixed data types on the columns: for instance, a column \"month\" can have both integer and string values, being \"object\" the data type associated in those cases. This ability could result in undesired side effects in several use cases, especially on data pipelines where it is necessary to know the type of data processed over the steps. This is a library that provides utils to handle Pandas DataFrames in a \"strict\" way regarding the data schema, so a DataFrame enforces a proper data type for each of its columns, as well as other related utils.","title":"StrictDataFrame"},{"location":"developers/#developers-guide","text":"","title":"Developers guide"},{"location":"developers/#installing-dev-mode","text":"Installing strictdf dev mode is done in the usual ways.","title":"Installing dev mode"},{"location":"developers/#github","text":"You can download the project from github repository and create a distribution wheel from code. Open a bash shell in the root of project and run: chmod +x script/library_create.sh ./script/library_create.sh if you are using windows os, you are starting very very bad. Anyway library_create.bat for windows is provided. Those commands should create two folders build and dist Now can install with pip following: pip install dist/strictdf-0.1.0-py3-none-any.whl[dev] Note: It is very important to install strictdf on the correct version of Python. StrictDataFrame requires Python>=3.9 . Note: Install strictdf on dev mode allow run test and check coverage.","title":"Github"},{"location":"developers/#run-tests","text":"To run test, You must download strictdf from github (previous section) and follow one of the following paths","title":"Run Tests"},{"location":"developers/#docker","text":"Using Dockerfile provided, You can build docker image, it's very easy, only open a bash shell and run: chmod +x script/build_docker.sh ./script/build_docker.sh Note: If you don't need spark , you can comment the lines indicated in the Dockerfile And when this ends: docker run -it strict_df_test","title":"Docker"},{"location":"developers/#hands","text":"With a shell in the root of the project, run: chmod +x script/create_env.sh chmod +x script/run_test.sh create_env.sh run_test.sh Note: To perform this, you need install python3.9 with pyenv and pip for that python version.","title":"Hands"}]}